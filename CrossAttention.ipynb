{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metadata import CarPassagePaths, CarEntityPaths\n",
    "from retrieval.tools import SearchTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata.\n",
    "datasets = {\n",
    "    'entity_train': \n",
    "    ('/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_entity_train_data/benchmarkY1_train_entity_1000.run',\n",
    "    '/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_entity_train_data/benchmarkY1_train_entity.qrels'),\n",
    "    \n",
    "    'entity_dev': \n",
    "    ('/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_entity_dev_data/benchmarkY1_dev_entity_1000.run',\n",
    "    '/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_entity_dev_data/benchmarkY1_dev_entity.qrels'),\n",
    "    \n",
    "    'entity_test': \n",
    "    ('/nfs/trec_car/data/entity_ranking/testY1_hierarchical_entity_data/testY1_hierarchical_entity_1000.run',\n",
    "    '/nfs/trec_car/data/entity_ranking/testY1_hierarchical_entity_data/testY1_hierarchical_entity.qrels'),\n",
    "    \n",
    "    'passage_train': \n",
    "    ('/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_passage_train_data/benchmarkY1_train_passage_1000.run',\n",
    "    '/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_passage_train_data/benchmarkY1_train_passage.qrels'),\n",
    "    \n",
    "    'passage_dev': \n",
    "    ('/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_passage_dev_data/benchmarkY1_dev_passage_1000.run',\n",
    "    '/nfs/trec_car/data/entity_ranking/benchmarkY1_hierarchical_passage_dev_data/benchmarkY1_dev_passage.qrels'),\n",
    "    \n",
    "    'passage_test': \n",
    "    ('/nfs/trec_car/data/entity_ranking/testY1_hierarchical_passage_data/testY1_hierarchical_passage_1000.run',\n",
    "    '/nfs/trec_car/data/entity_ranking/testY1_hierarchical_passage_data/testY1_hierarchical_passage.qrels')\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CarEntityPaths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-13d85cb63fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mindex_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCarPassagePaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'entity'\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mindex_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCarEntityPaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NOT VALID DATASET\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CarEntityPaths' is not defined"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "tokens = []\n",
    "\n",
    "for dataset_name, dataset_paths in datasets.items():\n",
    "    run_path = dataset_paths[0]\n",
    "    qrels_path = dataset_paths[1]\n",
    "    \n",
    "    # Define ranking type.\n",
    "    if 'passage' in dataset_name:\n",
    "        index_path = CarPassagePaths.index\n",
    "    elif 'entity'  in dataset_name:  \n",
    "        index_path = CarEntityPaths.index\n",
    "    else:\n",
    "        print(\"NOT VALID DATASET\")\n",
    "    \n",
    "    # Define dataset type.\n",
    "    if 'train' in dataset_name:\n",
    "        dataset_type = 'train'\n",
    "    elif 'dev'  in dataset_name:  \n",
    "         dataset_type = 'dev'\n",
    "    elif 'test'  in dataset_name:  \n",
    "         dataset_type = 'test'\n",
    "    else:\n",
    "        print(\"NOT VALID DATASET\")\n",
    "        \n",
    "    search_tools = SearchTools(index_path=index_path)\n",
    "    \n",
    "    qrels = search_tools.retrieval_utils.get_qrels_binary_dict(qrels_path=qrels_path)\n",
    "    \n",
    "    # Read run files\n",
    "    with open(run_path, 'r') as f:\n",
    "        for line in f:\n",
    "            query_encoded, _, doc_id, rank, score, _ = search_tools.retrieval_utils.unpack_run_line(line)\n",
    "\n",
    "            # Decode query.\n",
    "            try:\n",
    "                query = search_tools.decode_query_car(q=query_encoded)\n",
    "            except ValueError:\n",
    "                print(\"URL utf-8 decoding did not work with Pyserini's SimpleSearcher.search()/JString: {}\".format(query))\n",
    "                query = search_tools.process_query_car(q=query_encoded)    \n",
    "            \n",
    "            # Get relevant score\n",
    "            try:\n",
    "                if doc_id in qrels[query_encoded]:\n",
    "                    relevant = 1\n",
    "                else:\n",
    "                    relevant = 0\n",
    "            except:\n",
    "                relevant = 0\n",
    "            \n",
    "            # Get text.\n",
    "            text = search_tools.get_contents_from_docid(doc_id=doc_id)\n",
    "            if 'entity'  in dataset_name: \n",
    "                text = text.split('\\n')[0]\n",
    "\n",
    "            data.append([dataset_name, dataset_path, dataset_type, query, doc_id, rank, score, text, relevant])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "text = \"\"\"The Philippinesâ€”was almost entirely written by a single bot. Unlike Scots speakers, Ceb\"\"\"\n",
    "BERT_encodings = tokenizer.encode_plus(text=text, max_length=512, add_special_tokens=True, pad_to_max_length=True)\n",
    "\n",
    "\n",
    "class BertCLS(BertPreTrainedModel):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Initialise BERT setup.\n",
    "        self.bert = BertModel(config)\n",
    "        # Initialise BERT weights.\n",
    "        self.init_weights()\n",
    "    \n",
    "    def get_BERT_cls_vector(self, \n",
    "                            input_ids, \n",
    "                            attention_mask=None, \n",
    "                            token_type_ids=None, \n",
    "                            position_ids=None, \n",
    "                            head_mask=None,\n",
    "                            inputs_embeds=None):\n",
    "        \"\"\" Returns BERT pooled_output (i.e. CLS vector) applying dropout. \"\"\"\n",
    "        # Get BERT outputs.\n",
    "        outputs = self.bert(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask, \n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids, \n",
    "                            head_mask=head_mask, \n",
    "                            inputs_embeds=inputs_embeds)\n",
    "        # Apply dropout to pooled_output (i.e. CLS vector) and apply dropout.\n",
    "        return outputs[1]\n",
    "\n",
    "model = BertCLS.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = torch.tensor([BERT_encodings['input_ids']]*100)\n",
    "attention_mask = torch.tensor([BERT_encodings['attention_mask']]*100)\n",
    "token_type_ids = torch.tensor([BERT_encodings['token_type_ids']]*100)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    cls = model.get_BERT_cls_vector(input_ids=input_ids, \n",
    "                                        attention_mask=attention_mask, \n",
    "                                        token_type_ids=token_type_ids)\n",
    "    \n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 12, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "a.append([0,12,3])\n",
    "a.append([4,5,6])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_task_merge_env",
   "language": "python",
   "name": "multi_task_merge_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
