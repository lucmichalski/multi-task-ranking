FROM ubuntu:latest

MAINTAINER Iain Mackie

USER root

# Install essentials
RUN apt-get update && apt-get install -y \
    software-properties-common  \
    wget \
    make \
    gcc  \
    git

# Install Java 8
RUN apt-get update && apt-get install openjdk-8-jdk -y
ENV JAVA_VERSION="java-8-openjdk-amd64"
ENV JAVA_HOME=/usr/lib/jvm/$JAVA_VERSION
ENV PATH="$JAVA_HOME/bin:$PATH"

# Install maven 3.3.9
RUN wget --no-verbose -O /tmp/apache-maven-3.3.9-bin.tar.gz http://www-eu.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz && \
    tar xzf /tmp/apache-maven-3.3.9-bin.tar.gz -C /opt/ && \
    ln -s /opt/apache-maven-3.3.9 /opt/maven && \
    ln -s /opt/maven/bin/mvn /usr/local/bin  && \
    rm -f /tmp/apache-maven-3.3.9-bin.tar.gz
ENV MAVEN_HOME /opt/maven

# Install & build anserini
WORKDIR /home/
COPY ./anserini-anserini-0.5.1 /home/anserini/
WORKDIR /home/anserini/
RUN mvn clean package appassembler:assemble -DskipTests -Dmaven.javadoc.skip=true
WORKDIR /home/anserini/eval/
RUN tar xvfz trec_eval.9.0.4.tar.gz
WORKDIR /home/anserini/eval/trec_eval.9.0.4/
RUN make
WORKDIR /home/

# Install scala
RUN apt-get update && apt-get install scala -y

# Install python
RUN apt-get update && apt-get install -y python3 \
    python3-pip \
    python-setuptools \
    python-pip
RUN pip3 install \
    numpy \
    pandas \
    jupyter \
    jupyterlab \
    py4j \
    cbor \
    transformers \
    nltk \
    spacy \
    lmdb \
    torch \
    pyarrow \
    protobuf \
    pystream-protobuf==1.5.1 \
    pyserini==0.8.1.0

# Install Spark
ENV APACHE_SPARK_VERSION=2.4.5 \
    HADOOP_VERSION=2.7
RUN cd /tmp && \
    wget -q $(wget -qO- https://www.apache.org/dyn/closer.lua/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz\?as_json | \
    python3 -c "import sys, json; content=json.load(sys.stdin); print(content['preferred']+content['path_info'])") && \
    echo "2426a20c548bdfc07df288cd1d18d1da6b3189d0b78dee76fa034c52a4e02895f0ad460720c526f163ba63a17efae4764c46a1cd8f9b04c60f9937a554db85d2 *spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" | sha512sum -c - && \
    tar xzf spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz -C /usr/local/share/ --owner root --group root --no-same-owner && \
    rm spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
ENV SPARK_HOME=/usr/local/share/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}
ENV PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip
ENV SPARK_OPTS="--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info"
ENV PATH=$PATH:$SPARK_HOME/bin
ENV PYSPARK_PYTHON=python3

# Github credentials
RUN git config --global user.email "i.mackie@me.com"
RUN git config --global user.name "iain-mackie"